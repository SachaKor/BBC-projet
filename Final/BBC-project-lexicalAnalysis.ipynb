{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBC - Project: Analyse lexicale\n",
    "\n",
    "\n",
    "Pour cette partie du projet, notre objectif était de regarder si on peut sélectionner des gènes à pâtir de la documentation existante.<br>\n",
    "\n",
    "Pour faire ceci, nous avons décidé de calculer la similarité entre la description des gènes et une requête contentant des mots en rapport avec le cancer colorectal.<br>\n",
    "\n",
    "Cette analyse se fait en 5 étapes:\n",
    "- Extraction des gb_acc (gb access number) de chacun des gènes depuis le fichier de donnée.\n",
    "- Recherche du résumée (Entrezgene_summary) de chacun des gènes en utilisant le parser Bio.Entrez\n",
    "- Définir une requête (tableau de mots) qui sera le vecteur de requête\n",
    "- Vectoriser les résumés de chacun des gènes en utilisant le tf-idf (cela permet de donner un poids moins important aux mots qui apparaissent souvent). Nous avons utilisé la librairie NLTK pour faire ceci.\n",
    "- Calculer la similarité entre les vecteurs des documents et le vecteur de requête. Cela donnera des résultats entre 0 et 1 (0 = pas de similarité / pas de documentation, 1=timilarité totale).\n",
    "\n",
    "Une fois ces étapes effectuées, nous obtenons un tableau de chacun des gènes avec un score de similarité. Il nous reste plus qu'à sélectionner les 400 gènes avec le meilleur score (nous avons choisi 400 pour être en accord avec l'analyse statistique). Ils ont été sauvegardé dans le fichier gene_similartites_400.npy\n",
    "\n",
    "\n",
    "Nous aurions voulu tester l'efficacité de cette solution en regardant le pourcentage de gènes similaires entre les 2 méthodes. Si ce pourcentage est haut, cela signifie que l'analyse lexicale est pertinente (l'analyse lexicale avec l'analyse statistique). Cependant, nous n’avons pas eu le temps de faire cela.\n",
    "\n",
    "\n",
    "### Difficultés et problèmes rencontrés\n",
    "\n",
    "Le premier problème fut que le parser Entrez utilise les *gi* et que nous avions que les *gb_acc* comme identifiant. Nous avons donc dû trouver un moyen pour convertir les *gb_acc* en gi en utilisant le parser. Nous avons réussi à convertir une bonne partie des *id* mais pas tous. <br>\n",
    "Un second problème est que Entrez limite le nombre d'appel. Nous avons dû mettre un sleep(3) à chaque fois que le serveur nous revoyait une erreur \"connexion_timout\". <br>\n",
    "Nous avons résusi parser **37'023** gène sur les 50'000. <br>\n",
    "L'énorme quantité de données était, la lenteur et l'instabilité du parseur fût le plus gros problème. Le code a planté plusieurs fois pendant l'exécution. Et comme une exécution prend au moins 12h (juste pour convertir le gb_acc en gi).<br>\n",
    "\n",
    "### Ce qui reste à faire\n",
    "Comparer les résultats de l'analyse lexicale avec l'analyse statistique pour voir si l'analyse lexicale est pertinente.\n",
    "\n",
    "### Conclusion\n",
    "Nous ne pensons pas qu'une analyse lexicale soit pertinente pour les raisons suivantes:\n",
    "- Tous les gènes ne possèdent pas forcément une description.\n",
    "- Cela prend beaucoup trop de temps d'exécution.\n",
    "- Il n'est pas possible de trouver l'ig de certains gènes. Donc ils seront exclus de base même s'ils ont un lien.\n",
    "\n",
    "Hormis ça, d'un point de vue purement \"théorie du langage\", les meilleurs résultats sont plutôt bon avec une similarité de 0.876.\n",
    "\n",
    "C'était intéressant de faire ce travail. Mais le temps à disposition était trop limité. Le parseur nous a fait perdre énormément de temps. Mais nous pensons que la méthodologie employée est correcte.<br> Nous sommes tout de même un peu déçu de ne pas avoir pu faire l'analyse finale qui aurait pu dire si 'analyse lexicale est pertinente ou non.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les cellules qui prennent trop de temps d'exécution ou d'écriture dans les fichiers ont été désactivées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les requirement se trouvent dans le fichier: requirerments.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des gb_acc dans le fichier de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import Geo\n",
    "from Bio import Entrez\n",
    "import re\n",
    "import os, codecs \n",
    "import nltk\n",
    "from nltk.text import TextCollection\n",
    "from math import*\n",
    "\n",
    "def load_geo(myfile):\n",
    "    handle = open(myfile)\n",
    "    records = Geo.parse(handle)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-loading the data\n",
    "records = load_geo(DATA_PATH + 'GSE21510_family.soft')\n",
    "series_sample_id = []\n",
    "sample_titles = []\n",
    "genes = []\n",
    "gene_ids = []\n",
    "nb_cols = 0\n",
    "nb_rows = 0\n",
    "data = []\n",
    "for r in records:\n",
    "    rea = r.entity_attributes\n",
    "    if 'Series_geo_accession' in rea:\n",
    "        if rea['Series_geo_accession'] == 'GSE21510':\n",
    "            series_sample_id = rea['Series_sample_id']\n",
    "            nb_cols = len(series_sample_id)\n",
    "    if 'Sample_title' in rea:\n",
    "        sample_titles.append(rea['Sample_title'])\n",
    "        if 'sample_table_begin' in rea:\n",
    "            nb_rows = rea['Sample_data_row_count'] \n",
    "            data.append(r.table_rows)\n",
    "    if 'platform_table_begin' in rea:\n",
    "        print('found')\n",
    "        gene_ids.append(r.table_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the keys of this dict are gene IDs, the values are GB_ACCs\n",
    "genes_dict = {}\n",
    "for i, g in enumerate(gene_ids[0]):\n",
    "    if(i != 0): # do not inclide labels ('ID' & 'GB_ACC')\n",
    "        genes_dict[g[0]] = g[1]\n",
    "\n",
    "len(genes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération de la documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparateurs pour l'écriture dans les fichiers\n",
    "LINE_SEPARATOR = \"$$$\"\n",
    "CONETENT_SEPARATOR = \":::\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins d'accès pour les fichiers de données\n",
    "data_path = \"C:\\\\Users\\\\Jeremie Chatillon\\\\Documents\\\\HEIG\\\\BA-06\\\\BBC\\\\BBC-projet\\\\data\\\\\"\n",
    "#data_path = \"C:\\\\Users\\\\Basile\\\\Downloads\\\\Jérémie\\\\BBC-projet-lexical-analysis\\\\BBC-projet-lexical-analysis\\\\data\\\\\"\n",
    "data_file = \"geneDefinition_dev.dat\"\n",
    "gen_id_file = \"gen_id_dev.dat\"\n",
    "#data_file = \"geneDefinition_prod.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des tableaux de données\n",
    "gene_code = []\n",
    "gene_ids = []\n",
    "\n",
    "\n",
    "for key in genes_dict:\n",
    "    gene_code.append(genes_dict[key])\n",
    "    gene_ids.append(key)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Récupération des gi à partir des gb_acc\n",
    "gi_ids = []\n",
    "\n",
    "reset = 0\n",
    "count = 0\n",
    "ew = 0\n",
    "while count < len(gene_code):\n",
    "    try:\n",
    "        gi_ids.append(Entrez.read(Entrez.esearch(db='gene', term=gene_code[count], retmode='xml'))['IdList'][0])\n",
    "        count += 1\n",
    "        reset = 0\n",
    "    except Exception as e:\n",
    "        if str(e) == \"list index out of range\" :\n",
    "            count += 1\n",
    "            # Id qui n'as pas de doc\n",
    "            gi_ids.append('3310')\n",
    "            print(str(e))\n",
    "            continue\n",
    "            \n",
    "        reset += 1\n",
    "        print(\"Sleep\", reset)\n",
    "        time.sleep(3)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save gi in file \n",
    "\n",
    "fd = codecs.open(data_path + gen_id_file, 'w', 'utf8')\n",
    "\n",
    "str_ids = \"\"\n",
    "for gen_id in gi_ids:\n",
    "    str_ids += str(gen_id) + LINE_SEPARATOR\n",
    "fd.write(str_ids)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file with gi\n",
    "fd = codecs.open(data_path + gen_id_file, 'r', 'utf8')\n",
    "str_gi_ids = fd.read()\n",
    "fd.close()\n",
    "\n",
    "gi_ids = str_gi_ids.split(LINE_SEPARATOR)\n",
    "gi_ids = gi_ids[:len(gi_ids)-1]\n",
    "    \n",
    "gi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération et écriture de la documentation(Entrezgene_summary) de chacun des gènes avec le gi\n",
    "gen_datas_summary = []\n",
    "\n",
    "count = 0\n",
    "reset = 0\n",
    "fd = codecs.open(data_path + data_file, 'wb', 'utf8')\n",
    "tmp = datas[0][0] + CONETENT_SEPARATOR + datas[0][1] + CONETENT_SEPARATOR + datas[0][2] + LINE_SEPARATOR\n",
    "fd.write(tmp)\n",
    "while count < len(gi_ids):\n",
    "    try:\n",
    "        gi_id = gi_ids[count]\n",
    "        if gi_id != '3310':\n",
    "            handle = Entrez.efetch(db=\"gene\", id=gi_id, retmode=\"xml\")\n",
    "            records = Entrez.read(handle)\n",
    "            tmp = gene_ids[count] + CONETENT_SEPARATOR + gene_code[count] + CONETENT_SEPARATOR + records[0]['Entrezgene_summary'] + LINE_SEPARATOR\n",
    "            fd.write(tmp)\n",
    "        else:\n",
    "            tmp = gene_ids[count] + CONETENT_SEPARATOR + gene_code[count] + CONETENT_SEPARATOR + \" \" + LINE_SEPARATOR\n",
    "            fd.write(tmp)\n",
    "        print(count)\n",
    "        count += 1\n",
    "        reset = 0\n",
    "    except Exception as e:\n",
    "        if str(e) == \"'Entrezgene_summary'\":\n",
    "            count += 1\n",
    "            tmp = gene_ids[count] + CONETENT_SEPARATOR + gene_code[count] + CONETENT_SEPARATOR + \" \" + LINE_SEPARATOR\n",
    "            fd.write(tmp)\n",
    "            print(str(e))\n",
    "            continue\n",
    "        reset += 1\n",
    "        print(\"Sleep\", reset, e)\n",
    "        time.sleep(3)\n",
    "    \n",
    "fd.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse lexicale\n",
    "Nous avons sélectionné plusieurs mots liés au cancer colorectal. Nous avons utilisé la base de données MeSH pour obtenir ces mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_TO_SEARCH = ['cancer', 'colorectal', 'neoplasms', 'nonpolyposis', 'lynch' ]\n",
    "query_vector = [1 for i in range(len(WORD_TO_SEARCH))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecutre du fichier\n",
    "fd = codecs.open(data_path + data_file, 'r', 'utf8')\n",
    "war = fd.read()\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37023"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split des datas\n",
    "sents = war.split(LINE_SEPARATOR)\n",
    "# Supression de la dernière ligne vide\n",
    "sents = sents[:len(sents)-1]\n",
    "id_gb_texts = []\n",
    "for sent in sents:\n",
    "    dat = sent.split(CONETENT_SEPARATOR)\n",
    "\n",
    "    # Zone pour appliquer des fitres / lema / nomalisation\n",
    "    dat[2] = dat[2].lower()\n",
    "    id_gb_texts.append(dat)\n",
    "\n",
    "len(id_gb_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ID', 'GB_ACC', 'text'], ['1007_s_at', 'U48705', 'receptor tyrosine kinases play a key role in the communication of cells with their microenvironment. these kinases are involved in the regulation of cell growth, differentiation and metabolism. the protein encoded by this gene belongs to a subfamily of tyrosine kinase receptors with homology to dictyostelium discoideum protein discoidin i in their extracellular domain, and that are activated by various types of collagen. expression of this protein is restricted to epithelial cells, particularly in the kidney, lung, gastrointestinal tract, and brain. in addition, it has been shown to be significantly overexpressed in several human tumors. alternatively spliced transcript variants encoding different isoforms have been described for this gene. [provided by refseq, feb 2011]'], ['1053_at', 'M87338', 'this gene encodes a member of the activator 1 small subunits family. the elongation of primed dna templates by dna polymerase delta and epsilon requires the action of the accessory proteins, proliferating cell nuclear antigen (pcna) and replication factor c (rfc). replication factor c, also called activator 1, is a protein complex consisting of five distinct subunits. this gene encodes the 40 kd subunit, which has been shown to be responsible for binding atp and may help promote cell survival. disruption of this gene is associated with williams syndrome. alternatively spliced transcript variants encoding distinct isoforms have been described. a pseudogene of this gene has been defined on chromosome 2. [provided by refseq, jul 2013]'], ['117_at', 'X51757', ' '], ['121_at', 'X69699', 'this gene encodes a member of the paired box (pax) family of transcription factors. members of this gene family typically encode proteins that contain a paired box domain, an octapeptide, and a paired-type homeodomain. this nuclear protein is involved in thyroid follicular cell development and expression of thyroid-specific genes. mutations in this gene have been associated with thyroid dysgenesis, thyroid follicular carcinomas and atypical follicular thyroid adenomas. alternatively spliced transcript variants encoding different isoforms have been described. [provided by refseq, mar 2010]'], ['1255_g_at', 'L36861', 'this gene encodes an enzyme that plays a role in the recovery of retinal photoreceptors from photobleaching. this enzyme promotes the activity of retinal guanylyl cyclase-1 (gc1) at low calcium concentrations and inhibits gc1 at high calcium concentrations. mutations in this gene can cause cone dystrophy 3 and code-rod dystrophy 14. alternative splicing results in multiple transcript variants. [provided by refseq, jan 2016]'], ['1294_at', 'L13852', 'the modification of proteins with ubiquitin is an important cellular mechanism for targeting abnormal or short-lived proteins for degradation. ubiquitination involves at least three classes of enzymes: ubiquitin-activating enzymes, or e1s, ubiquitin-conjugating enzymes, or e2s, and ubiquitin-protein ligases, or e3s. this gene encodes a member of the e1 ubiquitin-activating enzyme family. the encoded enzyme is a retinoid target that triggers promyelocytic leukemia (pml)/retinoic acid receptor alpha (raralpha) degradation and apoptosis in acute promyelocytic leukemia, where it is involved in the conjugation of the ubiquitin-like interferon-stimulated gene 15 protein. [provided by refseq, jul 2008]'], ['1316_at', 'X55005', 'the protein encoded by this gene is a nuclear hormone receptor for triiodothyronine. it is one of the several receptors for thyroid hormone, and has been shown to mediate the biological activities of thyroid hormone. knockout studies in mice suggest that the different receptors, while having certain extent of redundancy, may mediate different functions of thyroid hormone. alternatively spliced transcript variants encoding distinct isoforms have been reported. [provided by refseq, jul 2008]'], ['1320_at', 'X79510', 'the protein encoded by this gene is a member of the protein tyrosine phosphatase (ptp) family. ptps are known to be signaling molecules that regulate a variety of cellular processes including cell growth, differentiation, mitotic cycle, and oncogenic transformation. this ptp contains an n-terminal domain, similar to cytoskeletal- associated proteins including band 4.1, ezrin, merlin, and radixin. this ptp was shown to specially interact with bmx/etk, a member of tec tyrosine kinase family characterized by a multimodular structures including ph, sh3, and sh2 domains. the interaction of this ptp with bmx kinase was found to increase the activation of stat3, but not stat2 kinase. studies of the similar gene in mice suggested the possible roles of this ptp in liver regeneration and spermatogenesis. [provided by refseq, jul 2008]'], ['1405_i_at', 'M21121', 'this gene is one of several chemokine genes clustered on the q-arm of chromosome 17. chemokines form a superfamily of secreted proteins involved in immunoregulatory and inflammatory processes. the superfamily is divided into four subfamilies based on the arrangement of the n-terminal cysteine residues of the mature peptide. this chemokine, a member of the cc subfamily, functions as a chemoattractant for blood monocytes, memory t helper cells and eosinophils. it causes the release of histamine from basophils and activates eosinophils. this cytokine is one of the major hiv-suppressive factors produced by cd8+ cells. it functions as one of the natural ligands for the chemokine receptor chemokine (c-c motif) receptor 5 (ccr5), and it suppresses in vitro replication of the r5 strains of hiv-1, which use ccr5 as a coreceptor. alternative splicing results in multiple transcript variants that encode different isoforms. [provided by refseq, jul 2013]']]\n"
     ]
    }
   ],
   "source": [
    "print(id_gb_texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37022"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création des collexion de texte à partir des documents\n",
    "text_arr = []\n",
    "for id_gb_text in id_gb_texts[1:]:\n",
    "    text_arr.append(id_gb_text[2])\n",
    "    \n",
    "text_collection = TextCollection(text_arr)\n",
    "len(text_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37023"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcul du TF-IDF pour chacun des documents\n",
    "tfidf_vector = [['id', 'tf-idf vector']]\n",
    "\n",
    "for id_gb_text in id_gb_texts[1:]:\n",
    "    vec = []\n",
    "    for word in WORD_TO_SEARCH:\n",
    "        tfidf = text_collection.tf_idf(word,id_gb_text[2] )\n",
    "        vec.append(tfidf)\n",
    "    tfidf_vector.append([id_gb_text[0], vec])\n",
    "        \n",
    "len(tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permet de calculer la similarité entre 2 vecteurs (requête et document)\n",
    "#http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/\n",
    "def square_rooted(x):\n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    "\n",
    "def cosine_similarity(x,y):\n",
    "    try:\n",
    "        numerator = sum(a*b for a,b in zip(x,y))\n",
    "        denominator = square_rooted(x)*square_rooted(y)\n",
    "        return round(numerator/float(denominator),3)\n",
    "    except:\n",
    "        return 0.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37023"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcule de la similarité entre tous les documents et la requête\n",
    "gene_similartites = [['id', 'cosSimilarity']]\n",
    "for gene in tfidf_vector[1:]:\n",
    "    dat = [gene[0], cosine_similarity(gene[1], query_vector)]\n",
    "    gene_similartites.append(dat)\n",
    "    \n",
    "len(gene_similartites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtre tous les gènes dont la similarité est de 0\n",
    "def filter_zero(array):\n",
    "    result = []\n",
    "    for xs in array:\n",
    "        if xs[1] != 0.0:\n",
    "            result.append(xs)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37023"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtre et trie tous les gènes\n",
    "gene_similartites_filtered1 = [['id', 'cosSimilarity']]\n",
    "# en\n",
    "tmp = (gene_similartites[1:])\n",
    "tmp.sort(key=lambda x: x[1],  reverse=True )\n",
    "gene_similartites_filtered1 += tmp\n",
    "len(gene_similartites_filtered1)\n",
    "\n",
    "len(gene_similartites_filtered1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des 400 meilleurs gènes\n",
    "np.save('gene_similartites_400', gene_similartites_filtered1[0:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des 400 meilleurs gènes\n",
    "data = np.load('gene_similartites_400.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id', 'cosSimilarity'],\n",
       "       ['209805_at', '0.876'],\n",
       "       ['1554742_at', '0.836']], dtype='<U13')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
